Below are the steps, for running LLM app using OLLMA:

- Open code space or vs code localy
- Downlaod the ollma for windows from github or in linux run command [curl -fsSL https://ollama.com/install.sh | sh] in your terminal
- Once the downlaod is done. Run command "ollama start"
- open a new terminal and run command "ollama run phi3" #replace the phi3 model if you want
- Type your question -> LLM will respond